{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS 3000 - Assignment 3\n",
    "\n",
    "**Student Name**: Group 34\n",
    "\n",
    "**Date**: 9/26/24\n",
    "\n",
    "\n",
    "### Submission Instructions\n",
    "Submit this `ipynb` file to canvas.\n",
    "\n",
    "The `ipynb` format stores outputs from the last time you ran the notebook.  (When you open a notebook it has the figures and outputs of the last time you ran it too).  To ensure that your submitted `ipynb` file represents your latest code, make sure to give a fresh run `Kernel > Restart & Run All` just before uploading the `ipynb` file to Canvas.\n",
    "\n",
    "### Academic Integrity\n",
    "\n",
    "**Writing your homework is an individual effort.**  You may discuss general python problems with other students but under no circumstances should you observe another student's code which was written for this assignment, from this year or past years.  Pop into office hours or DM us in MS Teams if you have a specific question about your work or if you would like another pair of eyes or talk through your code.\n",
    "\n",
    "Don't forget to cite websites which helped you solve a problem in a unique way.  You can do this in markdown near the code or with a simple one-line comment. You do not need to cite the official python documentation.\n",
    "\n",
    "**Documentation / style counts for credit**  Please refer to the Pep-8 style, to improve the readability and consistency of your Python code. For more information, read the following article [How to Write Beautiful Python Code With PEP 8](https://realpython.com/python-pep8/) or ask your TA's for tips.\n",
    "\n",
    "**NOTE:<span style='color:red'> Write python expressions to answer ALL questions below and ensure that you use the `print()` function to display the output.</span>** Each question should be answered in a new code cell. For example, your solution for question 1.1 should be in a different code cell from your solution for question 1.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 — The DS Problem\n",
    "\n",
    "In your own words, explain the Data Science problem that you were given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 — Prepare the Data (10 pts)\n",
    "\n",
    "Evaluate the dataset to determine if ALL variables are represented in their expected type. Convert variables to suitable data types (if needed).\n",
    "Analyze the data to determine what preprocessing steps are needed. Perform the required data preparation steps. At a minimum, ensure that you handle both missing and invalid values. Justify the approach that is taken to prepare the data for analysis.\n",
    "At a high level explain what the dataset is about and provide at least three visualizations to support your explanation of DS problem from Question 1. Note: this explanation and visualizations should be relevant to the DS Problem in question 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FL_DATE</th>\n",
       "      <th>CARRIER_CODE</th>\n",
       "      <th>TAIL_NUM</th>\n",
       "      <th>FL_NUM</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>ORIGIN_ST</th>\n",
       "      <th>DEST</th>\n",
       "      <th>DEST_ST</th>\n",
       "      <th>DEP_TIME</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>ARR_TIME</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>ELAPSED_TIME</th>\n",
       "      <th>DISTANCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>AA</td>\n",
       "      <td>N916NN</td>\n",
       "      <td>2311</td>\n",
       "      <td>TUS</td>\n",
       "      <td>AZ</td>\n",
       "      <td>ORD</td>\n",
       "      <td>IL</td>\n",
       "      <td>828.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1353.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>1437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>AA</td>\n",
       "      <td>N733UW</td>\n",
       "      <td>2315</td>\n",
       "      <td>PHX</td>\n",
       "      <td>AZ</td>\n",
       "      <td>DEN</td>\n",
       "      <td>CO</td>\n",
       "      <td>1907.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2159.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>AA</td>\n",
       "      <td>N140AN</td>\n",
       "      <td>2318</td>\n",
       "      <td>DFW</td>\n",
       "      <td>TX</td>\n",
       "      <td>LAX</td>\n",
       "      <td>CA</td>\n",
       "      <td>1904.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>1235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>AA</td>\n",
       "      <td>N925AN</td>\n",
       "      <td>2325</td>\n",
       "      <td>SNA</td>\n",
       "      <td>CA</td>\n",
       "      <td>DFW</td>\n",
       "      <td>TX</td>\n",
       "      <td>1729.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2215.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>AA</td>\n",
       "      <td>N143AN</td>\n",
       "      <td>2328</td>\n",
       "      <td>ATL</td>\n",
       "      <td>GA</td>\n",
       "      <td>LAX</td>\n",
       "      <td>CA</td>\n",
       "      <td>656.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>841.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>1947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897498</th>\n",
       "      <td>2019-01-31</td>\n",
       "      <td>UA</td>\n",
       "      <td>N73256</td>\n",
       "      <td>209</td>\n",
       "      <td>SNA</td>\n",
       "      <td>CA</td>\n",
       "      <td>SFO</td>\n",
       "      <td>CA</td>\n",
       "      <td>750.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>911.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897499</th>\n",
       "      <td>2019-01-31</td>\n",
       "      <td>UA</td>\n",
       "      <td>N39416</td>\n",
       "      <td>208</td>\n",
       "      <td>IAD</td>\n",
       "      <td>VA</td>\n",
       "      <td>LAX</td>\n",
       "      <td>CA</td>\n",
       "      <td>1855.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2148.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>2288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897500</th>\n",
       "      <td>2019-01-31</td>\n",
       "      <td>UA</td>\n",
       "      <td>N17104</td>\n",
       "      <td>207</td>\n",
       "      <td>BOS</td>\n",
       "      <td>MA</td>\n",
       "      <td>SFO</td>\n",
       "      <td>CA</td>\n",
       "      <td>802.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>386.0</td>\n",
       "      <td>2704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897501</th>\n",
       "      <td>2019-01-31</td>\n",
       "      <td>UA</td>\n",
       "      <td>N813UA</td>\n",
       "      <td>205</td>\n",
       "      <td>SFO</td>\n",
       "      <td>CA</td>\n",
       "      <td>PDX</td>\n",
       "      <td>OR</td>\n",
       "      <td>604.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>802.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897502</th>\n",
       "      <td>2019-01-31</td>\n",
       "      <td>UA</td>\n",
       "      <td>N75861</td>\n",
       "      <td>204</td>\n",
       "      <td>ORD</td>\n",
       "      <td>IL</td>\n",
       "      <td>LAX</td>\n",
       "      <td>CA</td>\n",
       "      <td>813.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>1744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1897503 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            FL_DATE CARRIER_CODE TAIL_NUM  FL_NUM ORIGIN ORIGIN_ST DEST  \\\n",
       "0        2019-10-01           AA   N916NN    2311    TUS        AZ  ORD   \n",
       "1        2019-10-01           AA   N733UW    2315    PHX        AZ  DEN   \n",
       "2        2019-10-01           AA   N140AN    2318    DFW        TX  LAX   \n",
       "3        2019-10-01           AA   N925AN    2325    SNA        CA  DFW   \n",
       "4        2019-10-01           AA   N143AN    2328    ATL        GA  LAX   \n",
       "...             ...          ...      ...     ...    ...       ...  ...   \n",
       "1897498  2019-01-31           UA   N73256     209    SNA        CA  SFO   \n",
       "1897499  2019-01-31           UA   N39416     208    IAD        VA  LAX   \n",
       "1897500  2019-01-31           UA   N17104     207    BOS        MA  SFO   \n",
       "1897501  2019-01-31           UA   N813UA     205    SFO        CA  PDX   \n",
       "1897502  2019-01-31           UA   N75861     204    ORD        IL  LAX   \n",
       "\n",
       "        DEST_ST  DEP_TIME  DEP_DELAY  ARR_TIME  ARR_DELAY  ELAPSED_TIME  \\\n",
       "0            IL     828.0        0.0    1353.0        0.0         205.0   \n",
       "1            CO    1907.0        0.0    2159.0        0.0         112.0   \n",
       "2            CA    1904.0      104.0    2016.0      101.0         192.0   \n",
       "3            TX    1729.0        4.0    2215.0        3.0         166.0   \n",
       "4            CA     656.0        0.0     841.0        0.0         285.0   \n",
       "...         ...       ...        ...       ...        ...           ...   \n",
       "1897498      CA     750.0        0.0     911.0        0.0          81.0   \n",
       "1897499      CA    1855.0        0.0    2148.0        0.0         353.0   \n",
       "1897500      CA     802.0        2.0    1128.0        0.0         386.0   \n",
       "1897501      OR     604.0        0.0     802.0        0.0         118.0   \n",
       "1897502      CA     813.0       18.0    1028.0        0.0         255.0   \n",
       "\n",
       "         DISTANCE  \n",
       "0            1437  \n",
       "1             602  \n",
       "2            1235  \n",
       "3            1205  \n",
       "4            1947  \n",
       "...           ...  \n",
       "1897498       372  \n",
       "1897499      2288  \n",
       "1897500      2704  \n",
       "1897501       550  \n",
       "1897502      1744  \n",
       "\n",
       "[1897503 rows x 14 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing data into a dataframe\n",
    "df = pd.read_csv('2019_ONTIME_REPORTING_FSW.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1897503"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing duplicate data rows from the dataframe\n",
    "df.drop_duplicates(inplace=True)\n",
    "# seeing how many rows remain in the dataframe\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there were no duplicate rows removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FL_DATE             0\n",
       "CARRIER_CODE        0\n",
       "TAIL_NUM         4791\n",
       "FL_NUM              0\n",
       "ORIGIN              0\n",
       "ORIGIN_ST           0\n",
       "DEST                0\n",
       "DEST_ST             0\n",
       "DEP_TIME        26707\n",
       "DEP_DELAY       26715\n",
       "ARR_TIME        28244\n",
       "ARR_DELAY       31884\n",
       "ELAPSED_TIME    31884\n",
       "DISTANCE            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking frequency of missing values of columns\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33745      6\n",
       "1369812    6\n",
       "1163400    6\n",
       "717776     6\n",
       "461086     6\n",
       "          ..\n",
       "636507     0\n",
       "636506     0\n",
       "636504     0\n",
       "636503     0\n",
       "1897502    0\n",
       "Length: 1897503, dtype: int64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indentifying the maximum number of missing variables in a row\n",
    "df.isnull().sum(axis=1).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FL_DATE         2019-10-07\n",
       "CARRIER_CODE            UA\n",
       "TAIL_NUM               NaN\n",
       "FL_NUM                 207\n",
       "ORIGIN                 BOS\n",
       "ORIGIN_ST               MA\n",
       "DEST                   SFO\n",
       "DEST_ST                 CA\n",
       "DEP_TIME               NaN\n",
       "DEP_DELAY              NaN\n",
       "ARR_TIME               NaN\n",
       "ARR_DELAY              NaN\n",
       "ELAPSED_TIME           NaN\n",
       "DISTANCE              2704\n",
       "Name: 33745, dtype: object"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are at maximum 6 variables missing at once from a row\n",
    "# looking at one of the rows where all six variables are missinig\n",
    "df.loc[33745]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks to be a widespread issue meaning that the best method to handle this missing data is deletion. I will remove all rows with NaN in the ELAPSED_TIME column as that is the highest column with the most number of variables deleted, tied with the ARR_DELAY column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1865619"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# should removed 31884 rows where there was a NaN value in the ELAPSED_TIME col\n",
    "df = df.drop(df[df['ELAPSED_TIME'].isnull()].index)\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31884"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# orginal number of rows minus the new number of rows should equate to 31884\n",
    "1897503-1865619"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1865619 entries, 0 to 1897502\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count    Dtype  \n",
      "---  ------        --------------    -----  \n",
      " 0   FL_DATE       1865619 non-null  object \n",
      " 1   CARRIER_CODE  1865619 non-null  object \n",
      " 2   TAIL_NUM      1865619 non-null  object \n",
      " 3   FL_NUM        1865619 non-null  int64  \n",
      " 4   ORIGIN        1865619 non-null  object \n",
      " 5   ORIGIN_ST     1865619 non-null  object \n",
      " 6   DEST          1865619 non-null  object \n",
      " 7   DEST_ST       1865619 non-null  object \n",
      " 8   DEP_TIME      1865619 non-null  float64\n",
      " 9   DEP_DELAY     1865619 non-null  float64\n",
      " 10  ARR_TIME      1865619 non-null  float64\n",
      " 11  ARR_DELAY     1865619 non-null  float64\n",
      " 12  ELAPSED_TIME  1865619 non-null  float64\n",
      " 13  DISTANCE      1865619 non-null  int64  \n",
      "dtypes: float64(5), int64(2), object(7)\n",
      "memory usage: 213.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# showing data type and non-null count of each variable in the dataframe\n",
    "df.info(show_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All null rows were removed with the removal of NaN values from ELAPSED_TIME as the issue was widespread throughout the data. \n",
    "\n",
    "When looking at the variables represented in the dataframe, one can see that all categorical variables (CARRIER_CODE, TAIL_NUM, ORIGIN, ORIGIN_ST, DEST, DEST_ST) are already properly assigned their corrected variable type in the data frame, object. The variables DEP_TIME, DEP_DELAY, ARR_TIME, ARR_DELAY, ELAPSED_TIME are currently represented as float variables when they can actually be represented as integers variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "# checking if all variables in DEP_TIME col are ints\n",
    "for i in df['DEP_TIME']:\n",
    "    if i.is_integer() == False:\n",
    "        count +=1\n",
    "# checking if all variables in DEP_DELAY col are ints\n",
    "for i in df['DEP_DELAY']:\n",
    "    if i.is_integer() == False:\n",
    "        count +=1\n",
    "# checking if all variables in ARR_TIME col are ints\n",
    "for i in df['ARR_TIME']:\n",
    "    if i.is_integer() == False:\n",
    "        count +=1\n",
    "# checking if all variables in ARR_DELAY col are ints\n",
    "for i in df['ARR_DELAY']:\n",
    "    if i.is_integer() == False:\n",
    "        count +=1\n",
    "# checking if all variables in ELAPSED_TIME col are ints\n",
    "for i in df['ELAPSED_TIME']:\n",
    "    if i.is_integer() == False:\n",
    "        count +=1\n",
    "        \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are no values that are not integers it is safe to convert the listed columns into integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting variables to their respected types\n",
    "df['DEP_TIME']  = df['DEP_TIME'].astype('int')\n",
    "df['DEP_DELAY']  = df['DEP_DELAY'].astype('int')\n",
    "df['ARR_TIME']  = df['ARR_TIME'].astype('int')\n",
    "df['ARR_DELAY']  = df['ARR_DELAY'].astype('int')\n",
    "df['ELAPSED_TIME']  = df['ELAPSED_TIME'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1865619 entries, 0 to 1897502\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count    Dtype \n",
      "---  ------        --------------    ----- \n",
      " 0   FL_DATE       1865619 non-null  object\n",
      " 1   CARRIER_CODE  1865619 non-null  object\n",
      " 2   TAIL_NUM      1865619 non-null  object\n",
      " 3   FL_NUM        1865619 non-null  int64 \n",
      " 4   ORIGIN        1865619 non-null  object\n",
      " 5   ORIGIN_ST     1865619 non-null  object\n",
      " 6   DEST          1865619 non-null  object\n",
      " 7   DEST_ST       1865619 non-null  object\n",
      " 8   DEP_TIME      1865619 non-null  int64 \n",
      " 9   DEP_DELAY     1865619 non-null  int64 \n",
      " 10  ARR_TIME      1865619 non-null  int64 \n",
      " 11  ARR_DELAY     1865619 non-null  int64 \n",
      " 12  ELAPSED_TIME  1865619 non-null  int64 \n",
      " 13  DISTANCE      1865619 non-null  int64 \n",
      "dtypes: int64(7), object(7)\n",
      "memory usage: 213.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# checking the data types to make sure they are updated \n",
    "df.info(show_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last data type to be addressed is the first column, the FL_DATE column. This column would best be represented by being represented as a DateTime variable in the data frame. This is a quick fix which will be taken care of in the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert 'FL_DATE' to datetime\n",
    "df['FL_DATE'] = pd.to_datetime(df['FL_DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1865619 entries, 0 to 1897502\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count    Dtype         \n",
      "---  ------        --------------    -----         \n",
      " 0   FL_DATE       1865619 non-null  datetime64[ns]\n",
      " 1   CARRIER_CODE  1865619 non-null  object        \n",
      " 2   TAIL_NUM      1865619 non-null  object        \n",
      " 3   FL_NUM        1865619 non-null  int64         \n",
      " 4   ORIGIN        1865619 non-null  object        \n",
      " 5   ORIGIN_ST     1865619 non-null  object        \n",
      " 6   DEST          1865619 non-null  object        \n",
      " 7   DEST_ST       1865619 non-null  object        \n",
      " 8   DEP_TIME      1865619 non-null  int64         \n",
      " 9   DEP_DELAY     1865619 non-null  int64         \n",
      " 10  ARR_TIME      1865619 non-null  int64         \n",
      " 11  ARR_DELAY     1865619 non-null  int64         \n",
      " 12  ELAPSED_TIME  1865619 non-null  int64         \n",
      " 13  DISTANCE      1865619 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(7), object(6)\n",
      "memory usage: 213.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# checking the data types to make sure they are updated \n",
    "df.info(show_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the variables have been updated to their correct types and missing data has been handled. It is now time to look for invalid data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FL_DATE</th>\n",
       "      <th>CARRIER_CODE</th>\n",
       "      <th>TAIL_NUM</th>\n",
       "      <th>FL_NUM</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>ORIGIN_ST</th>\n",
       "      <th>DEST</th>\n",
       "      <th>DEST_ST</th>\n",
       "      <th>DEP_TIME</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>ARR_TIME</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "      <th>ELAPSED_TIME</th>\n",
       "      <th>DISTANCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1865619</td>\n",
       "      <td>1865619</td>\n",
       "      <td>1865619</td>\n",
       "      <td>1.865619e+06</td>\n",
       "      <td>1865619</td>\n",
       "      <td>1865619</td>\n",
       "      <td>1865619</td>\n",
       "      <td>1865619</td>\n",
       "      <td>1.865619e+06</td>\n",
       "      <td>1.865619e+06</td>\n",
       "      <td>1.865619e+06</td>\n",
       "      <td>1.865619e+06</td>\n",
       "      <td>1.865619e+06</td>\n",
       "      <td>1.865619e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>4885</td>\n",
       "      <td>NaN</td>\n",
       "      <td>152</td>\n",
       "      <td>43</td>\n",
       "      <td>152</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>WN</td>\n",
       "      <td>N706SK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LAX</td>\n",
       "      <td>CA</td>\n",
       "      <td>LAX</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>543773</td>\n",
       "      <td>1734</td>\n",
       "      <td>NaN</td>\n",
       "      <td>216481</td>\n",
       "      <td>798690</td>\n",
       "      <td>216677</td>\n",
       "      <td>799137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2019-07-03 20:16:14.050972416</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.043568e+03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.341387e+03</td>\n",
       "      <td>1.311567e+01</td>\n",
       "      <td>1.470208e+03</td>\n",
       "      <td>1.272357e+01</td>\n",
       "      <td>1.748096e+02</td>\n",
       "      <td>1.146858e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.600000e+01</td>\n",
       "      <td>6.600000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2019-04-05 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.020000e+02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.130000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.050000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.400000e+01</td>\n",
       "      <td>4.510000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2019-07-05 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.633000e+03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.326000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.518000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.530000e+02</td>\n",
       "      <td>9.540000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2019-10-02 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.710000e+03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.757000e+03</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>1.936000e+03</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>2.440000e+02</td>\n",
       "      <td>1.744000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2019-12-31 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.910000e+03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.400000e+03</td>\n",
       "      <td>2.315000e+03</td>\n",
       "      <td>2.400000e+03</td>\n",
       "      <td>2.350000e+03</td>\n",
       "      <td>5.520000e+02</td>\n",
       "      <td>2.979000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.675336e+03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.190519e+02</td>\n",
       "      <td>4.355925e+01</td>\n",
       "      <td>5.591303e+02</td>\n",
       "      <td>4.306495e+01</td>\n",
       "      <td>9.273539e+01</td>\n",
       "      <td>7.564241e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              FL_DATE CARRIER_CODE TAIL_NUM        FL_NUM  \\\n",
       "count                         1865619      1865619  1865619  1.865619e+06   \n",
       "unique                            NaN           15     4885           NaN   \n",
       "top                               NaN           WN   N706SK           NaN   \n",
       "freq                              NaN       543773     1734           NaN   \n",
       "mean    2019-07-03 20:16:14.050972416          NaN      NaN  2.043568e+03   \n",
       "min               2019-01-01 00:00:00          NaN      NaN  1.000000e+00   \n",
       "25%               2019-04-05 00:00:00          NaN      NaN  7.020000e+02   \n",
       "50%               2019-07-05 00:00:00          NaN      NaN  1.633000e+03   \n",
       "75%               2019-10-02 00:00:00          NaN      NaN  2.710000e+03   \n",
       "max               2019-12-31 00:00:00          NaN      NaN  7.910000e+03   \n",
       "std                               NaN          NaN      NaN  1.675336e+03   \n",
       "\n",
       "         ORIGIN ORIGIN_ST     DEST  DEST_ST      DEP_TIME     DEP_DELAY  \\\n",
       "count   1865619   1865619  1865619  1865619  1.865619e+06  1.865619e+06   \n",
       "unique      152        43      152       43           NaN           NaN   \n",
       "top         LAX        CA      LAX       CA           NaN           NaN   \n",
       "freq     216481    798690   216677   799137           NaN           NaN   \n",
       "mean        NaN       NaN      NaN      NaN  1.341387e+03  1.311567e+01   \n",
       "min         NaN       NaN      NaN      NaN  1.000000e+00  0.000000e+00   \n",
       "25%         NaN       NaN      NaN      NaN  9.130000e+02  0.000000e+00   \n",
       "50%         NaN       NaN      NaN      NaN  1.326000e+03  0.000000e+00   \n",
       "75%         NaN       NaN      NaN      NaN  1.757000e+03  8.000000e+00   \n",
       "max         NaN       NaN      NaN      NaN  2.400000e+03  2.315000e+03   \n",
       "std         NaN       NaN      NaN      NaN  5.190519e+02  4.355925e+01   \n",
       "\n",
       "            ARR_TIME     ARR_DELAY  ELAPSED_TIME      DISTANCE  \n",
       "count   1.865619e+06  1.865619e+06  1.865619e+06  1.865619e+06  \n",
       "unique           NaN           NaN           NaN           NaN  \n",
       "top              NaN           NaN           NaN           NaN  \n",
       "freq             NaN           NaN           NaN           NaN  \n",
       "mean    1.470208e+03  1.272357e+01  1.748096e+02  1.146858e+03  \n",
       "min     1.000000e+00  0.000000e+00  2.600000e+01  6.600000e+01  \n",
       "25%     1.050000e+03  0.000000e+00  9.400000e+01  4.510000e+02  \n",
       "50%     1.518000e+03  0.000000e+00  1.530000e+02  9.540000e+02  \n",
       "75%     1.936000e+03  7.000000e+00  2.440000e+02  1.744000e+03  \n",
       "max     2.400000e+03  2.350000e+03  5.520000e+02  2.979000e+03  \n",
       "std     5.591303e+02  4.306495e+01  9.273539e+01  7.564241e+02  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing summary stats of all rows\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CHECKING_ST\n",
       "True    1865619\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of states to check against\n",
    "valid_states = ['CA', 'NV', 'AZ']\n",
    "\n",
    "# check if values in columns ORIGIN_ST OR DEST_ST are in  valid_states list\n",
    "df['CHECKING_ST'] = df['ORIGIN_ST'].isin(valid_states) | df['DEST_ST'].isin(valid_states)\n",
    "df['CHECKING_ST'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each flight in the data either took off or left from one of the states ['CA', 'NV', 'AZ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# checking if any flights left and landed at the same airport\n",
    "count = (df['ORIGIN'] == df['DEST']).sum()\n",
    "print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no flights left and landed at the same airport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 — (20 points)\n",
    "\n",
    "Explore patterns in the region i.e. the 3 states (AZ, NV, CA). Determine which region has the most air traffic. Comment on your findings and visualize the results. Note: it's important to explain your rational for determining what is \"the most air traffic\". For example, are you evaluating the frequency of flights or total flight time. Justify your response.\n",
    "For each region i.e. the 3 states (AZ, NV, CA), analyze the most popular outbound/destination airports. For example, if a flight originated in CA (at any of its airports), where do they often go? Comment on your findings and visualize the results for the top 5 destinations.\n",
    "For each region, calculate the proportion* of flights from each airline/operator. Visualize the top 10 results. Explain the results.\n",
    "*Hint: Don't forget that proportion is an explicit requirement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 — (20 points)\n",
    "\n",
    "Explore the carriers within the dataset and demonstrate at least TWO (2) patterns that you identified.\n",
    "Analyze the minimum, maximum and average arrival and departure delays for each Airline/Carrier. Visualize the top 10 results. Explain the patterns in the delays and demonstrate: 1) which carriers are more prone to flight delays and 2) are the delays occurring more frequently in certain regions**?\n",
    "**Tip: it is important to analyze the airlines across multiple airports and/or regions in order to conclude that they have a pattern of being late."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5 — (30 points)\n",
    "\n",
    "Evaluate which airlines have the best performance in the region. Display the top 10 airlines.\n",
    "Note: it's important to explain your rational for determining \"the best performance\".\n",
    "For each airline, ensure that you calculate their total flight hours for each month. Explain and visualize the results for the top 10 airlines. \n",
    "Hint: the total flight hours is not equivalent to the frequency of flights, and ensure that you display the total hours and not the total minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6 — (20 points)\n",
    "\n",
    "Select any THREE (3) aircraft***, and explore the data to analyze the following for each aircraft:\n",
    "\n",
    "Indicate which airline operates the selected aircraft and where it often travels.\n",
    "Arrival and departure delays at the airports where it traveled.\n",
    "Create summary statistics on the distance traveled.\n",
    "Analyze all the results in 6.1-6.3 to identify any patterns that are evident. Explain your findings and visualize ALL results.\n",
    "***Note: the TAIL_NUM can help you to identify each unique aircraft.\n",
    " \n",
    "\n",
    "Question 6 — Summary\n",
    "\n",
    "Summarize the overall analysis and share THREE (3) key findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpful resources \n",
    "Don't forget to cite websites which helped you solve a problem in a unique way.  You can do this in markdown near the code or with a simple one-line comment inside the code cell, or you can list them below. \n",
    "\n",
    "You do not need to cite the official python documentation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
